{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Using the csv file to get the directory url for each image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.7.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the image below, we can note the image name always starts with \"coarse_tilt_aligned_face\" followed by the face_id and then the original image name, all separated by a dot. We can use this pattern to create a new column called file_dir, this will enable us to easily read the images. The user_id is the folder where the image is contained.\n",
    "![image](sample.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from os import walk\n",
    "def get_label_list(dataset, data, dataset_dir):\n",
    "    file_names = \"coarse_tilt_aligned_face.\" \\\n",
    "                    + dataset['face_id'].astype(str) \\\n",
    "                    + '.'+dataset['original_image']\n",
    "\n",
    "    label_list = []\n",
    "    # because of the nature of tensorflow's image_dataset_from_directory function, the file order have to be rearranged\n",
    "    for (_,_,files) in walk(dataset_dir, topdown=True):\n",
    "        for count, file in enumerate(files):\n",
    "            data_value = dataset[file_names == file][data] # get age (for age data) or gender (for gender data)\n",
    "            if data_value.any(): # if data_value is found, add to label_list\n",
    "                label_list.append(data_value.to_numpy()[0])\n",
    "\n",
    "            # code to show verbose\n",
    "            completion_percentage = ((count + 1) / files.__len__()) * 100\n",
    "            print(f'Getting label_list - analyzing {data} images: {round(completion_percentage, 2)}%', end='\\r')\n",
    "        print()  # clear carriage\n",
    "\n",
    "    '''\n",
    "    dataset_dir = \"D:\\\\The Great Big World of Machine Learning\\Projects\\datasets\\AdienceBenchmarkGenderAndAgeClassification\\\\faces\"\n",
    "    folder = data['user_id']\n",
    "    separator = '.'\n",
    "    face_id = data['face_id']\n",
    "    orig_image = data['original_image']\n",
    "    file_name = []\n",
    "    for idx in range(len(folder)):\n",
    "        file_name.append(dataset_dir + '\\\\'+ folder[idx] + '\\\\'+\n",
    "                         \"coarse_tilt_aligned_face.\"+\n",
    "                         str(face_id[idx]) +separator+\n",
    "                         orig_image[idx])\n",
    "\n",
    "    return file_name\n",
    "    '''\n",
    "    return label_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def save_to_file(data):\n",
    "    save_path = \"D:\\\\The Great Big World of Machine Learning\\Projects\\datasets\\AdienceBenchmarkGenderAndAgeClassification\\\\ImgGenDataset\"\n",
    "    # set batch_sizes - [train, val, test]\n",
    "    batch_sizes = {'age':[15, 22, 21],\n",
    "                   'gender':[4, 25, 43]\n",
    "                   }\n",
    "\n",
    "    # decode images and add to dataset\n",
    "    dataset_path = \"D:\\The Great Big World of Machine Learning\" \\\n",
    "                  \"\\Projects\\datasets\\AdienceBenchmarkGenderAndAgeClassification\\\\new_dataset\" + '\\\\' + data\n",
    "    # for every data mode, get TTV folder\n",
    "    # use folder to get label_list and data_set\n",
    "    for mode in ['train', 'test', 'val']:\n",
    "        # get working directory\n",
    "        data_dir = dataset_path + '\\\\' + mode\n",
    "        '''\n",
    "        # fit label encoder to the label list of the dataset\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_list = get_label_list(dataset, data, dataset_dir=data_dir)\n",
    "        label_encoder.fit(label_list)\n",
    "        encoded_label_array = label_encoder.transform(label_list) # encode labels\n",
    "        # save the encoding to disk for use in inference\n",
    "        filename = save_path + '\\\\' + data +'_label_encoding.sav'\n",
    "        dump(label_encoder, open(filename, 'wb'))\n",
    "        '''\n",
    "\n",
    "        # set subset and validation_split for image_dataset_from_directory\n",
    "        # batch_sizes - [train, val, test]\n",
    "        if mode == 'train':\n",
    "            subset = 'training'\n",
    "            val_split=0.18\n",
    "            batch_size = batch_sizes[data][0]\n",
    "        elif mode == 'val':\n",
    "            subset = None\n",
    "            val_split = None\n",
    "            batch_size = batch_sizes[data][1]\n",
    "        else:\n",
    "            subset = None\n",
    "            val_split = None\n",
    "            batch_size = batch_sizes[data][2]\n",
    "        label_mode = 'int' if data == 'age' else 'binary' # set label mode for tensorflow image_dataset_from_directory\n",
    "        # found a bug in label_mode and class_names\n",
    "\n",
    "        # save images as tf.data.dataset\n",
    "        tf_dataset = tf.keras.utils.image_dataset_from_directory(directory=data_dir,\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 label_mode=label_mode,\n",
    "                                                                 image_size=(64, 64),\n",
    "                                                                 shuffle=True,\n",
    "                                                                 seed=7, # cuz 7 is my favourite number :-)\n",
    "                                                                 subset=subset,\n",
    "                                                                 validation_split=val_split)\n",
    "\n",
    "        tf.data.experimental.save(tf_dataset, save_path+\"\\\\\"+data+\"\\\\\"+mode) # save dataset to file\n",
    "        print(f\"{data} {mode} saved\")\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nage_data = pd.read_csv(\"age_data.csv\")\\nprint(age_data.head(3)) # preview the dataset\\nprint()\\n\\ngender_data = pd.read_csv(\"gender_data.csv\")\\nprint(gender_data.head()) # preview the dataset\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "age_data = pd.read_csv(\"age_data.csv\")\n",
    "print(age_data.head(3)) # preview the dataset\n",
    "print()\n",
    "\n",
    "gender_data = pd.read_csv(\"gender_data.csv\")\n",
    "print(gender_data.head()) # preview the dataset\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Age and Gender Data Partitioning\n",
    "We have to divide the data into 3 parts; Training data (for training), Validation data (during training), Test data (after training).Thishas already been donewhen the data was mvoed into the train, test, val folders (reference the 'Rearrange_Image_Files.py' file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Age (train, test, val) Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13035 files belonging to 8 classes.\n",
      "Using 10689 files for training.\n",
      "age train saved\n",
      "\n",
      "Found 2793 files belonging to 8 classes.\n",
      "age test saved\n",
      "\n",
      "Found 2794 files belonging to 8 classes.\n",
      "age val saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save age data\n",
    "save_to_file(data='age')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12244 files belonging to 2 classes.\n",
      "Using 10041 files for training.\n",
      "gender train saved\n",
      "\n",
      "Found 2623 files belonging to 2 classes.\n",
      "gender test saved\n",
      "\n",
      "Found 2625 files belonging to 2 classes.\n",
      "gender val saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save gender data\n",
    "save_to_file(data='gender')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}