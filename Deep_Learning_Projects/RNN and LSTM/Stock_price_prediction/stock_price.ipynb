{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3iW2W3OLFp8"
      },
      "source": [
        "Stock price prediction using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT5Y2J7YLWz0"
      },
      "source": [
        "Import library to collect and transfor data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zb0gUaoxLOQX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime\n",
        "from datetime import date, timedelta\n",
        "today = date.today()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6GLmsikL3IW"
      },
      "source": [
        "Download and Transform the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PhF6eZCML7cN",
        "outputId": "355b48f7-a7f7-435c-bba0-1cae9ba6b009"
      },
      "outputs": [],
      "source": [
        "#set a 500days (13 years) time frame to build the dataset on\n",
        "d1 = today.strftime(\"%Y-%m-%d\")\n",
        "end_date = d1\n",
        "d2 = date.today() - timedelta(days=5000)\n",
        "d2 = d2.strftime(\"%Y-%m-%d\")\n",
        "start_date = d2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = yf.download(tickers='ETH-USD', start=end_date, end=end_date, progress=False)\n",
        "df['Date'] = df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "tickers = ['BTC-USD', 'ETH-USD', 'USDT-USD', 'BNB-USD', 'USDC-USD']\n",
        "datasets = []\n",
        "\n",
        "## develop dataset for each ticker\n",
        "for ticker in tickers:\n",
        "    df = yf.download(tickers=ticker, start=start_date, end=end_date, progress=False)\n",
        "    #set date as index and move to new dataframe\n",
        "    df['Date'] = df.index\n",
        "    df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    #append ticker dataframe to datasets list\n",
        "    datasets.append(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1611</th>\n",
              "      <td>2022-04-08</td>\n",
              "      <td>3233.272461</td>\n",
              "      <td>3301.607422</td>\n",
              "      <td>3179.142334</td>\n",
              "      <td>3192.073975</td>\n",
              "      <td>3192.073975</td>\n",
              "      <td>17557050669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>2022-04-09</td>\n",
              "      <td>3191.976074</td>\n",
              "      <td>3261.963135</td>\n",
              "      <td>3187.469238</td>\n",
              "      <td>3261.916260</td>\n",
              "      <td>3261.916260</td>\n",
              "      <td>9908112156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1613</th>\n",
              "      <td>2022-04-10</td>\n",
              "      <td>3261.291504</td>\n",
              "      <td>3303.003174</td>\n",
              "      <td>3211.866943</td>\n",
              "      <td>3211.866943</td>\n",
              "      <td>3211.866943</td>\n",
              "      <td>10427054790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1614</th>\n",
              "      <td>2022-04-11</td>\n",
              "      <td>3209.576904</td>\n",
              "      <td>3214.461914</td>\n",
              "      <td>2962.756592</td>\n",
              "      <td>2981.052246</td>\n",
              "      <td>2981.052246</td>\n",
              "      <td>21891804831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1615</th>\n",
              "      <td>2022-04-12</td>\n",
              "      <td>2981.420654</td>\n",
              "      <td>3077.452637</td>\n",
              "      <td>2957.872314</td>\n",
              "      <td>3030.376465</td>\n",
              "      <td>3030.376465</td>\n",
              "      <td>20235707410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date         Open         High          Low        Close  \\\n",
              "1611 2022-04-08  3233.272461  3301.607422  3179.142334  3192.073975   \n",
              "1612 2022-04-09  3191.976074  3261.963135  3187.469238  3261.916260   \n",
              "1613 2022-04-10  3261.291504  3303.003174  3211.866943  3211.866943   \n",
              "1614 2022-04-11  3209.576904  3214.461914  2962.756592  2981.052246   \n",
              "1615 2022-04-12  2981.420654  3077.452637  2957.872314  3030.376465   \n",
              "\n",
              "        Adj Close       Volume  \n",
              "1611  3192.073975  17557050669  \n",
              "1612  3261.916260   9908112156  \n",
              "1613  3211.866943  10427054790  \n",
              "1614  2981.052246  21891804831  \n",
              "1615  3030.376465  20235707410  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "datasets[1].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPhXD9_BMGMq"
      },
      "source": [
        "Create a Candlestick chart to see the increase and decrease of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bMeFLsXzMSQM",
        "outputId": "660286ae-1916-42f0-9085-801aec1699ba"
      },
      "outputs": [],
      "source": [
        "# candlestick chart to have a better view of the increase and decrease of the stock price\n",
        "import plotly.graph_objects as go\n",
        "figure = go.Figure(data=[go.Candlestick(x=df['Date'], open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'])])\n",
        "figure.update_layout(title='AAPL Stock Price Analysis', xaxis_title='Date', yaxis_title='Price', xaxis_rangeslider_visible=False)\n",
        "figure.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hccIFsQTMXil"
      },
      "source": [
        "Check the correlation of the variable with Close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox5H37OPMcvU",
        "outputId": "304729c1-8c82-45bb-fc5f-74843be1d1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adj Close    1.000000\n",
            "Close        1.000000\n",
            "High         0.999498\n",
            "Low          0.999393\n",
            "Open         0.998838\n",
            "Volume       0.722272\n",
            "Name: Close, dtype: float64\n",
            "Adj Close    1.000000\n",
            "Close        1.000000\n",
            "Low          0.998984\n",
            "High         0.998957\n",
            "Open         0.997937\n",
            "Volume       0.549925\n",
            "Name: Close, dtype: float64\n",
            "Adj Close    1.000000\n",
            "Close        1.000000\n",
            "Open         0.677443\n",
            "High         0.621918\n",
            "Low          0.456403\n",
            "Volume      -0.130490\n",
            "Name: Close, dtype: float64\n",
            "Adj Close    1.000000\n",
            "Close        1.000000\n",
            "High         0.998892\n",
            "Low          0.998796\n",
            "Open         0.997642\n",
            "Volume       0.736578\n",
            "Name: Close, dtype: float64\n",
            "Adj Close    1.000000\n",
            "Close        1.000000\n",
            "Open         0.778438\n",
            "Low          0.553664\n",
            "High         0.190261\n",
            "Volume      -0.017885\n",
            "Name: Close, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# correlation with the Close column\n",
        "for ticker in datasets:\n",
        "    correl = ticker.corr()\n",
        "    print(correl['Close'].sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STclcXBAMj2I"
      },
      "source": [
        "Trainning LSTM for stock price prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PNap5A2CMoiV"
      },
      "outputs": [],
      "source": [
        "#separate data into features and labels\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "for data in datasets:\n",
        "    x_data.append(data[['Open', 'High', 'Low', 'Volume']].to_numpy())\n",
        "    y_data.append(data['Close'].to_numpy().reshape(-1, 1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training and the testing of the entire dataset of all tickers will be done in batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import necessary libraries for training\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.metrics import MeanAbsoluteError\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7FC0q3iM7YS"
      },
      "source": [
        "Prepare a neural network architecture for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxY3RDBN4hu",
        "outputId": "f6a9ca55-dd72-4c81-809b-09946d7fbacf"
      },
      "outputs": [],
      "source": [
        "def train_model(split_data, epochs=100):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, return_sequences=True, input_shape=(split_data[0].shape[1], 1)))\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(25))\n",
        "    model.add(Dense(1))\n",
        "    model.summary()\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=\"adam\", \n",
        "                loss=\"mean_absolute_error\", \n",
        "                metrics=['mean_absolute_error'])\n",
        "\n",
        "    # early stopping\n",
        "    early_stopping = EarlyStopping(\n",
        "                        monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
        "                    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(split_data[0], split_data[2], batch_size=1, epochs=100, callbacks=[early_stopping], validation_data=(split_data[1], split_data[3]))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oC5Q3NNN2rW"
      },
      "source": [
        "Train our neural network model for stock price prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibM4zNnHNDIW",
        "outputId": "9b02e709-23ae-4511-b9e2-468c92d5e1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 4, 128)            66560     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 25)                1625      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,619\n",
            "Trainable params: 117,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2212/2212 [==============================] - 21s 6ms/step - loss: 11203.6367 - mean_absolute_error: 11203.6367 - val_loss: 10934.9629 - val_mean_absolute_error: 10934.9629\n",
            "Epoch 2/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10572.3721 - mean_absolute_error: 10572.3721 - val_loss: 10521.9072 - val_mean_absolute_error: 10521.9072\n",
            "Epoch 3/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10342.3916 - mean_absolute_error: 10342.3916 - val_loss: 10448.9365 - val_mean_absolute_error: 10448.9365\n",
            "Epoch 4/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 10285.1777 - mean_absolute_error: 10285.1777 - val_loss: 10421.1260 - val_mean_absolute_error: 10421.1260\n",
            "Epoch 5/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10292.7510 - mean_absolute_error: 10292.7510 - val_loss: 10413.8682 - val_mean_absolute_error: 10413.8682\n",
            "Epoch 6/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10281.7676 - mean_absolute_error: 10281.7676 - val_loss: 10413.0547 - val_mean_absolute_error: 10413.0547\n",
            "Epoch 7/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 10298.6250 - mean_absolute_error: 10298.6250 - val_loss: 10416.0146 - val_mean_absolute_error: 10416.0146\n",
            "Epoch 8/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10280.9727 - mean_absolute_error: 10280.9727 - val_loss: 10411.5801 - val_mean_absolute_error: 10411.5801\n",
            "Epoch 9/100\n",
            "2212/2212 [==============================] - 14s 6ms/step - loss: 10248.9707 - mean_absolute_error: 10248.9707 - val_loss: 10408.9980 - val_mean_absolute_error: 10408.9980\n",
            "Epoch 10/100\n",
            "2212/2212 [==============================] - 14s 6ms/step - loss: 10279.6514 - mean_absolute_error: 10279.6514 - val_loss: 10409.7959 - val_mean_absolute_error: 10409.7959\n",
            "Epoch 11/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10299.3320 - mean_absolute_error: 10299.3320 - val_loss: 10411.3984 - val_mean_absolute_error: 10411.3984\n",
            "Epoch 12/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10285.8496 - mean_absolute_error: 10285.8496 - val_loss: 10419.7275 - val_mean_absolute_error: 10419.7275\n",
            "Epoch 13/100\n",
            "2212/2212 [==============================] - 14s 7ms/step - loss: 10317.7920 - mean_absolute_error: 10317.7920 - val_loss: 10410.6104 - val_mean_absolute_error: 10410.6104\n",
            "Epoch 14/100\n",
            "2212/2212 [==============================] - 14s 6ms/step - loss: 10308.5762 - mean_absolute_error: 10308.5762 - val_loss: 10411.8633 - val_mean_absolute_error: 10411.8633\n",
            "Epoch 15/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10276.5430 - mean_absolute_error: 10276.5430 - val_loss: 10411.1836 - val_mean_absolute_error: 10411.1836\n",
            "Epoch 16/100\n",
            "2212/2212 [==============================] - 14s 6ms/step - loss: 10272.8652 - mean_absolute_error: 10272.8652 - val_loss: 10410.0205 - val_mean_absolute_error: 10410.0205\n",
            "Epoch 17/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10293.4502 - mean_absolute_error: 10293.4502 - val_loss: 10256.3809 - val_mean_absolute_error: 10256.3809\n",
            "Epoch 18/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 10281.4170 - mean_absolute_error: 10281.4170 - val_loss: 10398.2334 - val_mean_absolute_error: 10398.2334\n",
            "Epoch 19/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 9512.3359 - mean_absolute_error: 9512.3359 - val_loss: 11219.3838 - val_mean_absolute_error: 11219.3838\n",
            "Epoch 20/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 8517.1279 - mean_absolute_error: 8517.1279 - val_loss: 10155.9814 - val_mean_absolute_error: 10155.9814\n",
            "Epoch 21/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 8270.3447 - mean_absolute_error: 8270.3447 - val_loss: 9999.7119 - val_mean_absolute_error: 9999.7119\n",
            "Epoch 22/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 8159.1382 - mean_absolute_error: 8159.1382 - val_loss: 7965.2939 - val_mean_absolute_error: 7965.2939\n",
            "Epoch 23/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7886.7388 - mean_absolute_error: 7886.7388 - val_loss: 7976.3452 - val_mean_absolute_error: 7976.3452\n",
            "Epoch 24/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 8045.9595 - mean_absolute_error: 8045.9595 - val_loss: 8029.4458 - val_mean_absolute_error: 8029.4458\n",
            "Epoch 25/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7954.2495 - mean_absolute_error: 7954.2495 - val_loss: 7953.3140 - val_mean_absolute_error: 7953.3140\n",
            "Epoch 26/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7889.4756 - mean_absolute_error: 7889.4756 - val_loss: 7989.7769 - val_mean_absolute_error: 7989.7769\n",
            "Epoch 27/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7827.7549 - mean_absolute_error: 7827.7549 - val_loss: 7790.6011 - val_mean_absolute_error: 7790.6011\n",
            "Epoch 28/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 8073.4702 - mean_absolute_error: 8073.4702 - val_loss: 8232.1582 - val_mean_absolute_error: 8232.1582\n",
            "Epoch 29/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 8032.3208 - mean_absolute_error: 8032.3208 - val_loss: 7941.9375 - val_mean_absolute_error: 7941.9375\n",
            "Epoch 30/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7992.5840 - mean_absolute_error: 7992.5840 - val_loss: 7784.5479 - val_mean_absolute_error: 7784.5479\n",
            "Epoch 31/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7876.4854 - mean_absolute_error: 7876.4854 - val_loss: 8354.2090 - val_mean_absolute_error: 8354.2090\n",
            "Epoch 32/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7862.8398 - mean_absolute_error: 7862.8398 - val_loss: 7944.5337 - val_mean_absolute_error: 7944.5337\n",
            "Epoch 33/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7823.0522 - mean_absolute_error: 7823.0522 - val_loss: 8753.8350 - val_mean_absolute_error: 8753.8350\n",
            "Epoch 34/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7895.1719 - mean_absolute_error: 7895.1719 - val_loss: 7970.9956 - val_mean_absolute_error: 7970.9956\n",
            "Epoch 35/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7796.1719 - mean_absolute_error: 7796.1719 - val_loss: 7927.1274 - val_mean_absolute_error: 7927.1274\n",
            "Epoch 36/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7890.7144 - mean_absolute_error: 7890.7144 - val_loss: 7949.0361 - val_mean_absolute_error: 7949.0361\n",
            "Epoch 37/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7981.4790 - mean_absolute_error: 7981.4790 - val_loss: 7911.1880 - val_mean_absolute_error: 7911.1880\n",
            "Epoch 38/100\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7774.2588 - mean_absolute_error: 7774.2588 - val_loss: 7966.4766 - val_mean_absolute_error: 7966.4766\n",
            "Epoch 39/100\n",
            "2212/2212 [==============================] - 13s 6ms/step - loss: 7918.7305 - mean_absolute_error: 7918.7305 - val_loss: 7940.3916 - val_mean_absolute_error: 7940.3916\n",
            "Epoch 40/100\n",
            "2205/2212 [============================>.] - ETA: 0s - loss: 7974.9624 - mean_absolute_error: 7974.9624Restoring model weights from the end of the best epoch: 30.\n",
            "2212/2212 [==============================] - 12s 6ms/step - loss: 7983.7324 - mean_absolute_error: 7983.7324 - val_loss: 8654.1162 - val_mean_absolute_error: 8654.1162\n",
            "Epoch 00040: early stopping\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 4, 128)            66560     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 25)                1625      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,619\n",
            "Trainable params: 117,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1292/1292 [==============================] - 10s 6ms/step - loss: 802.0579 - mean_absolute_error: 802.0579 - val_loss: 548.8255 - val_mean_absolute_error: 548.8255\n",
            "Epoch 2/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 606.0052 - mean_absolute_error: 606.0052 - val_loss: 358.1705 - val_mean_absolute_error: 358.1705\n",
            "Epoch 3/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 427.3733 - mean_absolute_error: 427.3733 - val_loss: 288.2083 - val_mean_absolute_error: 288.2083\n",
            "Epoch 4/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 414.5382 - mean_absolute_error: 414.5382 - val_loss: 677.6921 - val_mean_absolute_error: 677.6921\n",
            "Epoch 5/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 409.0820 - mean_absolute_error: 409.0820 - val_loss: 371.6927 - val_mean_absolute_error: 371.6927\n",
            "Epoch 6/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 339.6991 - mean_absolute_error: 339.6991 - val_loss: 173.6963 - val_mean_absolute_error: 173.6963\n",
            "Epoch 7/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 327.2476 - mean_absolute_error: 327.2476 - val_loss: 234.6618 - val_mean_absolute_error: 234.6618\n",
            "Epoch 8/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 370.5011 - mean_absolute_error: 370.5011 - val_loss: 267.7808 - val_mean_absolute_error: 267.7808\n",
            "Epoch 9/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 341.7404 - mean_absolute_error: 341.7404 - val_loss: 191.3895 - val_mean_absolute_error: 191.3895\n",
            "Epoch 10/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 352.9019 - mean_absolute_error: 352.9019 - val_loss: 270.5636 - val_mean_absolute_error: 270.5636\n",
            "Epoch 11/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 301.5617 - mean_absolute_error: 301.5617 - val_loss: 276.2302 - val_mean_absolute_error: 276.2302\n",
            "Epoch 12/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 332.8676 - mean_absolute_error: 332.8676 - val_loss: 271.2150 - val_mean_absolute_error: 271.2150\n",
            "Epoch 13/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 331.2556 - mean_absolute_error: 331.2556 - val_loss: 167.7129 - val_mean_absolute_error: 167.7129\n",
            "Epoch 14/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 322.0755 - mean_absolute_error: 322.0755 - val_loss: 177.9184 - val_mean_absolute_error: 177.9184\n",
            "Epoch 15/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 295.1944 - mean_absolute_error: 295.1944 - val_loss: 246.5017 - val_mean_absolute_error: 246.5017\n",
            "Epoch 16/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 323.7119 - mean_absolute_error: 323.7119 - val_loss: 194.2121 - val_mean_absolute_error: 194.2121\n",
            "Epoch 17/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 265.1921 - mean_absolute_error: 265.1921 - val_loss: 163.8377 - val_mean_absolute_error: 163.8377\n",
            "Epoch 18/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 284.4002 - mean_absolute_error: 284.4002 - val_loss: 268.9749 - val_mean_absolute_error: 268.9749\n",
            "Epoch 19/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 337.3719 - mean_absolute_error: 337.3719 - val_loss: 156.6232 - val_mean_absolute_error: 156.6232\n",
            "Epoch 20/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 269.2799 - mean_absolute_error: 269.2799 - val_loss: 214.9390 - val_mean_absolute_error: 214.9390\n",
            "Epoch 21/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 305.1122 - mean_absolute_error: 305.1122 - val_loss: 371.1788 - val_mean_absolute_error: 371.1788\n",
            "Epoch 22/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 346.1706 - mean_absolute_error: 346.1706 - val_loss: 321.2757 - val_mean_absolute_error: 321.2757\n",
            "Epoch 23/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 311.4653 - mean_absolute_error: 311.4653 - val_loss: 136.3181 - val_mean_absolute_error: 136.3181\n",
            "Epoch 24/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 283.7726 - mean_absolute_error: 283.7726 - val_loss: 149.3356 - val_mean_absolute_error: 149.3356\n",
            "Epoch 25/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 320.4480 - mean_absolute_error: 320.4480 - val_loss: 187.0320 - val_mean_absolute_error: 187.0320\n",
            "Epoch 26/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 295.6623 - mean_absolute_error: 295.6623 - val_loss: 296.2147 - val_mean_absolute_error: 296.2147\n",
            "Epoch 27/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 312.8078 - mean_absolute_error: 312.8078 - val_loss: 158.1986 - val_mean_absolute_error: 158.1986\n",
            "Epoch 28/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 289.6227 - mean_absolute_error: 289.6227 - val_loss: 185.7681 - val_mean_absolute_error: 185.7681\n",
            "Epoch 29/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 271.0354 - mean_absolute_error: 271.0354 - val_loss: 150.9264 - val_mean_absolute_error: 150.9264\n",
            "Epoch 30/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 270.6313 - mean_absolute_error: 270.6313 - val_loss: 367.7014 - val_mean_absolute_error: 367.7014\n",
            "Epoch 31/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 251.1521 - mean_absolute_error: 251.1521 - val_loss: 171.7946 - val_mean_absolute_error: 171.7946\n",
            "Epoch 32/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 281.9413 - mean_absolute_error: 281.9413 - val_loss: 219.1347 - val_mean_absolute_error: 219.1347\n",
            "Epoch 33/100\n",
            "1290/1292 [============================>.] - ETA: 0s - loss: 294.4065 - mean_absolute_error: 294.4065Restoring model weights from the end of the best epoch: 23.\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 294.4337 - mean_absolute_error: 294.4337 - val_loss: 174.9452 - val_mean_absolute_error: 174.9452\n",
            "Epoch 00033: early stopping\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 4, 128)            66560     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 25)                1625      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,619\n",
            "Trainable params: 117,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1292/1292 [==============================] - 10s 6ms/step - loss: 0.0895 - mean_absolute_error: 0.0895 - val_loss: 0.0288 - val_mean_absolute_error: 0.0288\n",
            "Epoch 2/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 0.0124 - mean_absolute_error: 0.0124 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
            "Epoch 3/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
            "Epoch 4/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0096 - val_mean_absolute_error: 0.0096\n",
            "Epoch 5/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0052 - val_mean_absolute_error: 0.0052\n",
            "Epoch 6/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0041 - val_mean_absolute_error: 0.0041\n",
            "Epoch 7/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0091 - val_mean_absolute_error: 0.0091\n",
            "Epoch 8/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
            "Epoch 9/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0047 - val_mean_absolute_error: 0.0047\n",
            "Epoch 10/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
            "Epoch 11/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0046 - val_mean_absolute_error: 0.0046\n",
            "Epoch 12/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0098 - val_mean_absolute_error: 0.0098\n",
            "Epoch 13/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 0.0052 - mean_absolute_error: 0.0052 - val_loss: 0.0105 - val_mean_absolute_error: 0.0105\n",
            "Epoch 14/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 0.0051 - mean_absolute_error: 0.0051 - val_loss: 0.0071 - val_mean_absolute_error: 0.0071\n",
            "Epoch 15/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
            "Epoch 16/100\n",
            "1286/1292 [============================>.] - ETA: 0s - loss: 0.0053 - mean_absolute_error: 0.0053Restoring model weights from the end of the best epoch: 6.\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 0.0053 - mean_absolute_error: 0.0053 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
            "Epoch 00016: early stopping\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 4, 128)            66560     \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 25)                1625      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,619\n",
            "Trainable params: 117,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1292/1292 [==============================] - 11s 7ms/step - loss: 66.1454 - mean_absolute_error: 66.1454 - val_loss: 21.1621 - val_mean_absolute_error: 21.1621\n",
            "Epoch 2/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 29.4991 - mean_absolute_error: 29.4991 - val_loss: 22.7266 - val_mean_absolute_error: 22.7266\n",
            "Epoch 3/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 31.4688 - mean_absolute_error: 31.4688 - val_loss: 23.0041 - val_mean_absolute_error: 23.0041\n",
            "Epoch 4/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 24.5999 - mean_absolute_error: 24.5999 - val_loss: 18.0403 - val_mean_absolute_error: 18.0403\n",
            "Epoch 5/100\n",
            "1292/1292 [==============================] - 8s 7ms/step - loss: 23.7639 - mean_absolute_error: 23.7639 - val_loss: 14.0660 - val_mean_absolute_error: 14.0660\n",
            "Epoch 6/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 32.5762 - mean_absolute_error: 32.5762 - val_loss: 39.2982 - val_mean_absolute_error: 39.2982\n",
            "Epoch 7/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 27.7700 - mean_absolute_error: 27.7700 - val_loss: 18.8242 - val_mean_absolute_error: 18.8242\n",
            "Epoch 8/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 24.1535 - mean_absolute_error: 24.1535 - val_loss: 27.2430 - val_mean_absolute_error: 27.2430\n",
            "Epoch 9/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 25.6291 - mean_absolute_error: 25.6291 - val_loss: 12.0542 - val_mean_absolute_error: 12.0542\n",
            "Epoch 10/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 22.9539 - mean_absolute_error: 22.9539 - val_loss: 12.5335 - val_mean_absolute_error: 12.5335\n",
            "Epoch 11/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 23.1371 - mean_absolute_error: 23.1371 - val_loss: 19.7787 - val_mean_absolute_error: 19.7787\n",
            "Epoch 12/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 21.8379 - mean_absolute_error: 21.8379 - val_loss: 8.8248 - val_mean_absolute_error: 8.8248\n",
            "Epoch 13/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 21.6592 - mean_absolute_error: 21.6592 - val_loss: 9.2893 - val_mean_absolute_error: 9.2893\n",
            "Epoch 14/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 24.3720 - mean_absolute_error: 24.3720 - val_loss: 19.2930 - val_mean_absolute_error: 19.2930\n",
            "Epoch 15/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 24.1607 - mean_absolute_error: 24.1607 - val_loss: 19.8806 - val_mean_absolute_error: 19.8806\n",
            "Epoch 16/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 21.8126 - mean_absolute_error: 21.8126 - val_loss: 8.5887 - val_mean_absolute_error: 8.5887\n",
            "Epoch 17/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 21.0663 - mean_absolute_error: 21.0663 - val_loss: 9.7665 - val_mean_absolute_error: 9.7665\n",
            "Epoch 18/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 20.4468 - mean_absolute_error: 20.4468 - val_loss: 12.5273 - val_mean_absolute_error: 12.5273\n",
            "Epoch 19/100\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 20.1722 - mean_absolute_error: 20.1722 - val_loss: 10.3909 - val_mean_absolute_error: 10.3909\n",
            "Epoch 20/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 21.9177 - mean_absolute_error: 21.9177 - val_loss: 15.6280 - val_mean_absolute_error: 15.6280\n",
            "Epoch 21/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 20.6834 - mean_absolute_error: 20.6834 - val_loss: 7.7892 - val_mean_absolute_error: 7.7892\n",
            "Epoch 22/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 20.8916 - mean_absolute_error: 20.8916 - val_loss: 13.3083 - val_mean_absolute_error: 13.3083\n",
            "Epoch 23/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 20.8788 - mean_absolute_error: 20.8788 - val_loss: 12.7986 - val_mean_absolute_error: 12.7986\n",
            "Epoch 24/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 19.6792 - mean_absolute_error: 19.6792 - val_loss: 12.6712 - val_mean_absolute_error: 12.6712\n",
            "Epoch 25/100\n",
            "1292/1292 [==============================] - 8s 6ms/step - loss: 18.9542 - mean_absolute_error: 18.9542 - val_loss: 9.8693 - val_mean_absolute_error: 9.8693\n",
            "Epoch 26/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 19.9978 - mean_absolute_error: 19.9978 - val_loss: 14.2264 - val_mean_absolute_error: 14.2264\n",
            "Epoch 27/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 19.1228 - mean_absolute_error: 19.1228 - val_loss: 13.3312 - val_mean_absolute_error: 13.3312\n",
            "Epoch 28/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 17.8763 - mean_absolute_error: 17.8763 - val_loss: 11.7972 - val_mean_absolute_error: 11.7972\n",
            "Epoch 29/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 20.5287 - mean_absolute_error: 20.5287 - val_loss: 25.3561 - val_mean_absolute_error: 25.3561\n",
            "Epoch 30/100\n",
            "1292/1292 [==============================] - 7s 6ms/step - loss: 21.6756 - mean_absolute_error: 21.6756 - val_loss: 10.9294 - val_mean_absolute_error: 10.9294\n",
            "Epoch 31/100\n",
            "1284/1292 [============================>.] - ETA: 0s - loss: 21.0538 - mean_absolute_error: 21.0538Restoring model weights from the end of the best epoch: 21.\n",
            "1292/1292 [==============================] - 9s 7ms/step - loss: 20.9816 - mean_absolute_error: 20.9816 - val_loss: 12.0868 - val_mean_absolute_error: 12.0868\n",
            "Epoch 00031: early stopping\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 4, 128)            66560     \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 25)                1625      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,619\n",
            "Trainable params: 117,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1026/1026 [==============================] - 10s 7ms/step - loss: 0.1015 - mean_absolute_error: 0.1015 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
            "Epoch 2/100\n",
            "1026/1026 [==============================] - 7s 7ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n",
            "Epoch 3/100\n",
            "1026/1026 [==============================] - 7s 7ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0050 - val_mean_absolute_error: 0.0050\n",
            "Epoch 4/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0083 - val_mean_absolute_error: 0.0083\n",
            "Epoch 5/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
            "Epoch 6/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0044 - val_mean_absolute_error: 0.0044\n",
            "Epoch 7/100\n",
            "1026/1026 [==============================] - 7s 7ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0075 - val_mean_absolute_error: 0.0075\n",
            "Epoch 8/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0089 - val_mean_absolute_error: 0.0089\n",
            "Epoch 9/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0040 - val_mean_absolute_error: 0.0040\n",
            "Epoch 10/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.0062 - val_mean_absolute_error: 0.0062\n",
            "Epoch 11/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0086 - val_mean_absolute_error: 0.0086\n",
            "Epoch 12/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0069 - val_mean_absolute_error: 0.0069\n",
            "Epoch 13/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.0045 - val_mean_absolute_error: 0.0045\n",
            "Epoch 14/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0042 - val_mean_absolute_error: 0.0042\n",
            "Epoch 15/100\n",
            "1026/1026 [==============================] - 7s 6ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0049 - val_mean_absolute_error: 0.0049\n",
            "Epoch 16/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0038 - val_mean_absolute_error: 0.0038\n",
            "Epoch 17/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0097 - val_mean_absolute_error: 0.0097\n",
            "Epoch 18/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0038 - val_mean_absolute_error: 0.0038\n",
            "Epoch 19/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0047 - val_mean_absolute_error: 0.0047\n",
            "Epoch 20/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.0039 - val_mean_absolute_error: 0.0039\n",
            "Epoch 21/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.0051 - val_mean_absolute_error: 0.0051\n",
            "Epoch 22/100\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0041 - val_mean_absolute_error: 0.0041\n",
            "Epoch 23/100\n",
            "1026/1026 [==============================] - 7s 7ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0078 - val_mean_absolute_error: 0.0078\n",
            "Epoch 24/100\n",
            "1026/1026 [==============================] - 7s 7ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0054 - val_mean_absolute_error: 0.0054\n",
            "Epoch 25/100\n",
            "1026/1026 [==============================] - 7s 6ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0059 - val_mean_absolute_error: 0.0059\n",
            "Epoch 26/100\n",
            "1026/1026 [==============================] - 7s 6ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.0065 - val_mean_absolute_error: 0.0065\n",
            "Epoch 27/100\n",
            "1026/1026 [==============================] - 7s 6ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
            "Epoch 28/100\n",
            "1017/1026 [============================>.] - ETA: 0s - loss: 0.0057 - mean_absolute_error: 0.0057Restoring model weights from the end of the best epoch: 18.\n",
            "1026/1026 [==============================] - 6s 6ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.0064 - val_mean_absolute_error: 0.0064\n",
            "Epoch 00028: early stopping\n"
          ]
        }
      ],
      "source": [
        "models = []\n",
        "eval_score = []\n",
        "\n",
        "for (xdata, ydata) in zip(x_data, y_data):\n",
        "    #split data into training and testing\n",
        "    split_data = train_test_split(xdata, ydata, test_size=0.2, random_state=42)\n",
        "    #train model\n",
        "    model = train_model(split_data)\n",
        "    models.append(model)\n",
        "    #evaluate performance\n",
        "    preds = model.predict(split_data[1])\n",
        "    eval_score.append(MAE(split_data[3], preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDwu901lOhW4"
      },
      "source": [
        "Test giving input values according to the features that we have used to train this model and predicting the final result of the prediction of **Close value**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7784.548754479958,\n",
              " 136.31814167823322,\n",
              " 0.004122312790081825,\n",
              " 7.789193747956076,\n",
              " 0.003766464815993253]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('BTC-USD', 7784.548754479958), ('ETH-USD', 136.31814167823322), ('USDT-USD', 0.004122312790081825), ('BNB-USD', 7.789193747956076), ('USDC-USD', 0.003766464815993253)]\n"
          ]
        }
      ],
      "source": [
        "scores = list(zip(tickers, eval_score))\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lssD3C15Pvov",
        "outputId": "08650a0b-3f8a-4c97-eb7d-b650da118a96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[432.2462]], dtype=float32)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "# features = [Open, High, Low, Volume]\n",
        "features = np.array([[413.93, 421.69, 411.08, 1924450176]])\n",
        "models[3].predict(features) # return the Close value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BTC-USD_no_adjustments\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BTC-USD_no_adjustments\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018C05268308> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018C0527CA48> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ETH-USD_no_adjustments\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ETH-USD_no_adjustments\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018C4C8C4A88> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018C659BBEC8> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: USDT-USD_no_adjustments\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: USDT-USD_no_adjustments\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018C6D57C248> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018C6D71AAC8> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BNB-USD_no_adjustments\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: BNB-USD_no_adjustments\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018D6F210608> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018D79B0BB88> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: USDC-USD_no_adjustments\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: USDC-USD_no_adjustments\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018D89B7AF48> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000018D9AF6CAC8> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "#save the model for inference\n",
        "for idx, model in enumerate(models):\n",
        "    model.save(tickers[idx]+\"_no_adjustments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_model = tf.keras.models.load_model('saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_preds = new_model.predict(x_test)\n",
        "print(score(y_test, new_preds))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "stock_price.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
