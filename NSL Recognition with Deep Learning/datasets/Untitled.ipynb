{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\r\n",
    "import numpy as np\r\n",
    "from keras.utils import np_utils, to_categorical\r\n",
    "from keras.preprocessing import image\r\n",
    "from os import listdir\r\n",
    "from os.path import isdir, join"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def path_to_tensor(img_path, size):\r\n",
    "    # loads RGB image as PIL.Image.Image type\r\n",
    "    img = image.load_img(img_path, target_size=(size, size))\r\n",
    "    # convert PIL.Image.Image type to 3D tensor\r\n",
    "    x = image.img_to_array(img)\r\n",
    "    # convert 3D tensor to 4D tensor \r\n",
    "    return np.expand_dims(x, axis=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def paths_to_tensor(img_paths, size=50):\r\n",
    "    list_of_tensors = [path_to_tensor(img_path, size) for img_path in img_paths]\r\n",
    "    return np.vstack(list_of_tensors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "container_path='D:\\Git Repos\\Machine_Learning\\ASL Recognition with Deep Learning\\datasets'\r\n",
    "folders=['Letter_A', 'Letter_B', 'Letter_C', 'Letter_D', 'Letter_E']\r\n",
    "size=2000\r\n",
    "test_split=0.2\r\n",
    "seed=0\r\n",
    "\"\"\"\r\n",
    "Loads sign language dataset.\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "filenames, labels = [], []\r\n",
    "\r\n",
    "for label, folder in enumerate(folders):\r\n",
    "    folder_path = join(container_path, folder)\r\n",
    "    images = [join(folder_path, d)\r\n",
    "                    for d in sorted(listdir(folder_path))]\r\n",
    "    labels.extend(len(images) * [label])\r\n",
    "    filenames.extend(images)\r\n",
    "\r\n",
    "random.seed(seed)\r\n",
    "data = list(zip(filenames, labels))\r\n",
    "random.shuffle(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "parkito_list = []\r\n",
    "\r\n",
    "for letter in range(65, 91):\r\n",
    "    parkito_list.append(chr(letter))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "parkito_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "filenames, labels = zip(*data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Get the images\r\n",
    "x = paths_to_tensor(filenames)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x = x.astype('float32')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "x = x/255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "len(y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Store the one-hot targets\r\n",
    "y = np.array(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "x_train = np.array(x[:int(len(x) * (1 - test_split))])\r\n",
    "y_train = np.array(y[:int(len(x) * (1 - test_split))])\r\n",
    "x_test = np.array(x[int(len(x) * (1 - test_split)):])\r\n",
    "y_test = np.array(y[int(len(x) * (1 - test_split)):])\r\n",
    "\r\n",
    "\r\n",
    "#return (x_train, y_train), (x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('deep_learning': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "a327d6382053ebb6ff465b84c1aa5589cee973caaef7c9c3e26de320dbb2fc23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}